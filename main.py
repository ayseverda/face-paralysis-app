# ... existing code ...
import glob
import time
from pathlib import Path

import cv2
import mediapipe as mp
import numpy as np

# "Sonrakine geÃ§" butonu iÃ§in alan ve mouse state
NEXT_BTN_RECT = (20, 260, 260, 300)  # (x1, y1, x2, y2)
next_clicked = False


def mouse_callback(event, x, y, flags, param):
    global next_clicked
    if event == cv2.EVENT_LBUTTONDOWN:
        x1, y1, x2, y2 = NEXT_BTN_RECT
        if x1 <= x <= x2 and y1 <= y <= y2:
            next_clicked = True

mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

mp_face = mp.solutions.face_mesh.FaceMesh(
    static_image_mode=True,
    max_num_faces=1,
    refine_landmarks=True,
)

LANDMARKS = {
    "left_eye": [33, 133, 160, 159, 158, 153, 144, 145],
    "right_eye": [263, 362, 385, 380, 381, 382, 373, 390],
    # AÄŸÄ±z kÃ¶ÅŸeleri (gÃ¼lÃ¼mseme asimetrisi iÃ§in)
    "mouth_corners": [61, 291],
    # Ãœst / alt dudak (aÄŸÄ±z aÃ§Ä±klÄ±ÄŸÄ± iÃ§in)
    "mouth_vertical": [13, 14],
    # KaÅŸ iÃ§in birden fazla nokta (sol / saÄŸ)
    "brow_left": [70, 63],
    "brow_right": [300, 293],
}

# Solâ€“saÄŸ simetrik noktalar: gÃ¶z, kaÅŸ, aÄŸÄ±z, yanak/burun Ã§evresi
LEFT_RIGHT_PAIRS = [
    (33, 263),   # dÄ±ÅŸ gÃ¶z kÃ¶ÅŸeleri
    (133, 362),  # iÃ§ gÃ¶z kÃ¶ÅŸeleri
    (159, 386),  # Ã¼st gÃ¶z kapaÄŸÄ±
    (145, 374),  # alt gÃ¶z kapaÄŸÄ±
    (61, 291),   # aÄŸÄ±z kÃ¶ÅŸeleri
    (40, 270),   # nazolabial Ã§izgi Ã§evresi
    (70, 300),   # kaÅŸ orta
    (63, 293),   # kaÅŸ iÃ§
    (105, 334),  # kaÅŸ dÄ±ÅŸ
]


def calc_distance(a, b):
    return np.linalg.norm(np.array(a) - np.array(b))


def extract_metrics(get_point):
    # GÃ–ZLER: her gÃ¶z iÃ§in "eye aspect ratio" (yÃ¼kseklik / geniÅŸlik), sonra iki gÃ¶zÃ¼n oran farkÄ±
    left_eye = np.array([get_point(i) for i in LANDMARKS["left_eye"]])
    right_eye = np.array([get_point(i) for i in LANDMARKS["right_eye"]])

    def eye_ear(eye_pts):
        # 0-3 geniÅŸlik, (1-5 ve 2-4) Ã§iftleri yÃ¼kseklik
        width = calc_distance(eye_pts[0], eye_pts[3])
        h1 = calc_distance(eye_pts[1], eye_pts[5])
        h2 = calc_distance(eye_pts[2], eye_pts[4])
        height = (h1 + h2) / 2.0
        return height / (width + 1e-6)

    ear_left = eye_ear(left_eye)
    ear_right = eye_ear(right_eye)
    eye_diff = abs(ear_left - ear_right) / (max(ear_left, ear_right) + 1e-6)

    # AÄžIZ: hem gÃ¼lÃ¼mseme asimetrisi hem de aÄŸÄ±z aÃ§Ä±klÄ±ÄŸÄ±
    mouth_left = get_point(LANDMARKS["mouth_corners"][0])
    mouth_right = get_point(LANDMARKS["mouth_corners"][1])
    upper_lip = get_point(LANDMARKS["mouth_vertical"][0])
    lower_lip = get_point(LANDMARKS["mouth_vertical"][1])

    mouth_width = calc_distance(mouth_left, mouth_right) + 1e-6
    # kÃ¶ÅŸeler arasÄ± yÃ¼kseklik farkÄ± / geniÅŸlik -> gÃ¼lÃ¼mseme asimetrisi
    smile_asym = abs(mouth_left[1] - mouth_right[1]) / mouth_width
    # Ã¼st-alt dudak arasÄ± mesafe / geniÅŸlik -> aÄŸÄ±z aÃ§Ä±klÄ±ÄŸÄ± (gÃ¼lÃ¼mseme, dudak bÃ¼zme vs)
    mouth_open = calc_distance(upper_lip, lower_lip) / mouth_width
    # ikisini birleÅŸtiren tek bir aÄŸÄ±z metriÄŸi
    mouth_diff = 0.5 * smile_asym + 0.5 * mouth_open

    # KAÅžLAR: kaÅŸlarÄ±n gÃ¶z merkezine gÃ¶re yÃ¼ksekliÄŸi (sol / saÄŸ farkÄ±)
    brow_left_pts = np.array([get_point(i) for i in LANDMARKS["brow_left"]])
    brow_right_pts = np.array([get_point(i) for i in LANDMARKS["brow_right"]])

    left_eye_center = np.mean(left_eye, axis=0)
    right_eye_center = np.mean(right_eye, axis=0)

    left_brow_y = np.mean(brow_left_pts[:, 1])
    right_brow_y = np.mean(brow_right_pts[:, 1])

    left_eye_width = calc_distance(left_eye[0], left_eye[3]) + 1e-6
    right_eye_width = calc_distance(right_eye[0], right_eye[3]) + 1e-6

    # gÃ¶z merkezine gÃ¶re normalize edilmiÅŸ kaÅŸ yÃ¼ksekliÄŸi
    left_brow_h = (left_eye_center[1] - left_brow_y) / left_eye_width
    right_brow_h = (right_eye_center[1] - right_brow_y) / right_eye_width

    brow_diff = abs(left_brow_h - right_brow_h) / (max(abs(left_brow_h), abs(right_brow_h)) + 1e-6)

    # TÃœM YÃœZ Ä°Ã‡Ä°N GLOBAL ASÄ°METRÄ°:
    # BirÃ§ok solâ€“saÄŸ Ã§iftinin dikey asimetrisini alÄ±p ortalÄ±yoruz.
    pair_asym = []
    for li, ri in LEFT_RIGHT_PAIRS:
        lp = get_point(li)
        rp = get_point(ri)
        base = calc_distance(lp, rp) + 1e-6
        dy = abs(lp[1] - rp[1]) / base  # dikey fark / aralarÄ±ndaki mesafe
        pair_asym.append(dy)
    global_asym = float(np.mean(pair_asym)) if pair_asym else 0.0

    return eye_diff, mouth_diff, brow_diff, global_asym


def compute_score(eye_diff, mouth_diff, brow_diff, global_asym):
    # Global asimetriyi de skora dahil et
    return (
        0.3 * eye_diff
        + 0.2 * mouth_diff
        + 0.1 * brow_diff
        + 0.4 * global_asym
    )


def analyze_face(image_path: Path):
    image = cv2.imread(str(image_path))
    if image is None:
        return None, f"GÃ¶rÃ¼ntÃ¼ okunamadÄ±: {image_path}"

    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = mp_face.process(rgb)
    if not results.multi_face_landmarks:
        return None, "YÃ¼z bulunamadÄ±"

    h, w, _ = image.shape
    landmarks = results.multi_face_landmarks[0]

    def get_point(idx):
        pt = landmarks.landmark[idx]
        return np.array([pt.x * w, pt.y * h])

    eye_diff, mouth_diff, brow_diff, global_asym = extract_metrics(get_point)
    score = compute_score(eye_diff, mouth_diff, brow_diff, global_asym)
    return score, {
        "eye_diff": eye_diff,
        "mouth_diff": mouth_diff,
        "brow_diff": brow_diff,
        "global_asym": global_asym,
    }


def analyze_frame(frame):
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = mp_face.process(rgb)
    if not results.multi_face_landmarks:
        return None, "YÃ¼z bulunamadÄ±"

    h, w, _ = frame.shape
    landmarks = results.multi_face_landmarks[0]

    # BaÅŸÄ±n eÄŸiklik (roll) aÃ§Ä±sÄ±nÄ± yaklaÅŸÄ±k hesapla (solâ€“saÄŸ gÃ¶z merkezlerine bakarak)
    left_eye_pts = np.array(
        [[landmarks.landmark[i].x * w, landmarks.landmark[i].y * h] for i in LANDMARKS["left_eye"]]
    )
    right_eye_pts = np.array(
        [[landmarks.landmark[i].x * w, landmarks.landmark[i].y * h] for i in LANDMARKS["right_eye"]]
    )
    left_center = left_eye_pts.mean(axis=0)
    right_center = right_eye_pts.mean(axis=0)
    dx = right_center[0] - left_center[0]
    dy = right_center[1] - left_center[1]
    roll_deg = float(np.degrees(np.arctan2(dy, dx)))

    # Kafa fazla eÄŸikse bu kareyi skora katma (sadece uyarÄ± yaz)
    if abs(roll_deg) > 8.0:
        warning = f"Bas cok egik (roll={roll_deg:+.1f}Â°) - lutfen daha dik durun"
        cv2.putText(
            frame,
            warning,
            (20, 60),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (0, 0, 255),
            2,
        )
        return None, {"reason": "head_tilt", "roll_deg": roll_deg}

    # YÃ¼z mesh noktalarÄ±nÄ± ve konturlarÄ± kareye Ã§iz
    mp_drawing.draw_landmarks(
        image=frame,
        landmark_list=landmarks,
        connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,
        landmark_drawing_spec=None,
        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style(),
    )
    mp_drawing.draw_landmarks(
        image=frame,
        landmark_list=landmarks,
        connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,
        landmark_drawing_spec=None,
        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style(),
    )

    # Ã–ZEL OLARAK KULLANILAN NOKTALARI VURGULA:
    # GÃ¶zler (mavi), AÄŸÄ±z (kÄ±rmÄ±zÄ±), KaÅŸlar (yeÅŸil)

    # GÃ¶zler (mavi)
    for idx in LANDMARKS["left_eye"] + LANDMARKS["right_eye"]:
        pt = landmarks.landmark[idx]
        pt_px = (int(pt.x * w), int(pt.y * h))
        cv2.circle(frame, pt_px, 2, (255, 0, 0), -1)

    # AÄŸÄ±z: kÃ¶ÅŸeler + Ã¼st/alt dudak (kÄ±rmÄ±zÄ±)
    mouth_pts = []
    for idx in LANDMARKS["mouth_corners"] + LANDMARKS["mouth_vertical"]:
        pt = landmarks.landmark[idx]
        pt_px = (int(pt.x * w), int(pt.y * h))
        mouth_pts.append(pt_px)
        cv2.circle(frame, pt_px, 4, (0, 0, 255), -1)
    # kÃ¶ÅŸeler arasÄ±nda Ã§izgi
    if len(mouth_pts) >= 2:
        cv2.line(frame, mouth_pts[0], mouth_pts[1], (0, 0, 255), 2)

    # KaÅŸ (yeÅŸil)
    for idx in LANDMARKS["brow_left"] + LANDMARKS["brow_right"]:
        pt = landmarks.landmark[idx]
        pt_px = (int(pt.x * w), int(pt.y * h))
        cv2.circle(frame, pt_px, 3, (0, 255, 0), -1)

    def get_point(idx):
        pt = landmarks.landmark[idx]
        return np.array([pt.x * w, pt.y * h])

    eye_diff, mouth_diff, brow_diff, global_asym = extract_metrics(get_point)
    score = compute_score(eye_diff, mouth_diff, brow_diff, global_asym)
    return score, {
        "eye_diff": eye_diff,
        "mouth_diff": mouth_diff,
        "brow_diff": brow_diff,
        "global_asym": global_asym,
    }


def collect_scores():
    felc_scores, saglikli_scores = [], []
    for path in sorted(Path("ornekler/felc").glob("*")):
        score, _ = analyze_face(path)
        if score is not None:
            felc_scores.append(score)
    for path in sorted(Path("ornekler/saglikli").glob("*")):
        score, _ = analyze_face(path)
        if score is not None:
            saglikli_scores.append(score)
    return felc_scores, saglikli_scores


def calibrate_from_dataset():
    """
    ornekler/felc ve ornekler/saglikli klasÃ¶rlerinden skor istatistikleri toplar,
    otomatik bir global eÅŸik ve kalibrasyon parametreleri dÃ¶ner.
    """
    felc_scores, saglikli_scores = collect_scores()
    if not felc_scores or not saglikli_scores:
        print("Kalibrasyon iÃ§in yeterli veri yok.")
        return None

    felc_scores = np.array(felc_scores, dtype=float)
    saglikli_scores = np.array(saglikli_scores, dtype=float)

    felc_mean = float(np.mean(felc_scores))
    sag_mean = float(np.mean(saglikli_scores))

    # Basit global eÅŸik: iki ortalamanÄ±n ortasÄ±
    global_threshold = (felc_mean + sag_mean) / 2.0

    print("\n[Kalibrasyon]")
    print(f"- FelÃ§   ort/min/max: {felc_mean:.3f}  {np.min(felc_scores):.3f}  {np.max(felc_scores):.3f}")
    print(f"- SaÄŸlÄ±klÄ± ort/min/max: {sag_mean:.3f}  {np.min(saglikli_scores):.3f}  {np.max(saglikli_scores):.3f}")
    print(f"- Ã–nerilen global eÅŸik (midpoint): {global_threshold:.3f}")

    return {
        "felc_mean": felc_mean,
        "sag_mean": sag_mean,
        "global_threshold": global_threshold,
    }


def score_to_probability(score, felc_mean, sag_mean):
    """
    Skoru [0,1] arasÄ±nda 'felÃ§ olasÄ±lÄ±ÄŸÄ±'na map eder.
    sag_mean civarÄ± â‰ˆ 0, felc_mean civarÄ± â‰ˆ 1 olacak ÅŸekilde lineer Ã¶lÃ§ekleme.
    """
    denom = (felc_mean - sag_mean)
    if abs(denom) < 1e-6:
        return 0.5  # veri anlamsÄ±zsa nÃ¶tr

    p = (score - sag_mean) / denom
    p = float(np.clip(p, 0.0, 1.0))
    return p


def run_webcam(calibration=None, duration=5.0):
    """
    calibration: None ise eski sabit eÅŸik (0.25) kullanÄ±lÄ±r.
                 dict ise calibrate_from_dataset() Ã§Ä±ktÄ±sÄ± beklenir.
    """
    global next_clicked

    if calibration is not None:
        threshold = calibration["global_threshold"]
        felc_mean = calibration["felc_mean"]
        sag_mean = calibration["sag_mean"]
        print(f"\nKamera, kalibre edilmiÅŸ global eÅŸik ile Ã§alÄ±ÅŸÄ±yor: threshold={threshold:.3f}")
    else:
        threshold = 0.25
        felc_mean = None
        sag_mean = None
        print(f"\nKamera, sabit eÅŸik ile Ã§alÄ±ÅŸÄ±yor: threshold={threshold:.3f}")

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Kamera aÃ§Ä±lamadÄ±")
        return

    window_name = "Yuz Felci Analizi - Egzersiz"
    cv2.namedWindow(window_name)
    cv2.setMouseCallback(window_name, mouse_callback)

    # Her faz iÃ§in: ekrandaki metin, anahtar isim, renk
    # 0. faz: NÃ–TR â€“ yÃ¼zÃ¼n baÅŸlangÄ±Ã§ hali
    phases = [
        ("LÃ¼tfen NÃ–TR bakÄ±n, yÃ¼zÃ¼nÃ¼zÃ¼ rahat birakÄ±n ðŸ™‚", "notr", (200, 200, 200)),
        ("LÃ¼tfen GÃœLÃœMSEYÄ°N ðŸ˜€", "gÃ¼lÃ¼mseme", (0, 255, 255)),
        ("LÃ¼tfen KAÅžLARINIZI KALDIRIN ðŸ˜¯", "kaÅŸ_kaldÄ±rma", (0, 255, 0)),
        ("LÃ¼tfen KAÅžLARINIZI Ã‡ATIN ðŸ˜ ", "kaÅŸ_Ã§atma", (0, 165, 255)),
        ("LÃ¼tfen DUDAKLARINIZI BÃœZÃœN ðŸ˜—", "dudak_bÃ¼zme", (255, 0, 255)),
    ]

    print("Kamera baÅŸlatÄ±ldÄ±. SÄ±rayla ÅŸu hareketleri yapman istenecek:")
    print("0) NÃ¶tr bakÄ±ÅŸ, 1) GÃ¼lÃ¼mseme, 2) KaÅŸ kaldÄ±rma, 3) KaÅŸ Ã§atma, 4) Dudak bÃ¼zme")
    print("Her faz, 'Sonrakine geÃ§' butonuna tÄ±klayana veya 'n' tusuna basana kadar sÃ¼recek.\n")

    # Toplam skorlar ve fazlara gÃ¶re skorlar
    all_scores = []
    all_probs = []
    phase_scores = {key: [] for _, key, _ in phases}
    phase_probs = {key: [] for _, key, _ in phases}

    # Faz bazlÄ± bileÅŸen metrikleri (nÃ¶tre gÃ¶re fark bakmak iÃ§in)
    phase_components = {
        key: {"eye": [], "mouth": [], "brow": [], "yuz": []}
        for _, key, _ in phases
    }

    stop_all = False

    for instruction, phase_key, color in phases:
        print(f"Faz: {phase_key} -> {instruction}")
        next_clicked = False

        while True:
            ret, frame = cap.read()
            if not ret:
                stop_all = True
                break

            score, details = analyze_frame(frame)

            # Kafa Ã§ok eÄŸikse details dict deÄŸil, string/dict uyarÄ± gelebiliyor; o kareyi atla
            if score is not None and isinstance(details, dict):
                all_scores.append(score)
                phase_scores[phase_key].append(score)

                # bileÅŸenleri kaydet (nÃ¶tre gÃ¶re fark iÃ§in)
                phase_components[phase_key]["eye"].append(details["eye_diff"])
                phase_components[phase_key]["mouth"].append(details["mouth_diff"])
                phase_components[phase_key]["brow"].append(details["brow_diff"])
                phase_components[phase_key]["yuz"].append(details["global_asym"])

                # EÄŸer kalibrasyon varsa olasÄ±lÄ±k hesapla
                if felc_mean is not None and sag_mean is not None:
                    prob = score_to_probability(score, felc_mean, sag_mean)
                    all_probs.append(prob)
                    phase_probs[phase_key].append(prob)
                    prob_text = f"FelÃ§ olasiligi: {prob*100:5.1f}%"
                else:
                    prob = None
                    prob_text = ""

                status = "FELÃ‡ (anlÄ±k)" if score > threshold else "SaÄŸlÄ±klÄ± (anlÄ±k)"
                info = (
                    f"skor={score:.3f}  "
                    f"gÃ¶z={details['eye_diff']:.3f}  "
                    f"aÄŸÄ±z={details['mouth_diff']:.3f}  "
                    f"kaÅŸ={details['brow_diff']:.3f}  "
                    f"yÃ¼z={details['global_asym']:.3f}"
                )

                # --- AÄžIZ ve KAÅž Ä°Ã‡Ä°N SERT FELÃ‡ SÄ°NYALÄ° ---
                strong_mouth = details["mouth_diff"] > 0.10
                strong_brow = details["brow_diff"] > 0.10

                if strong_mouth or strong_brow:
                    alert = "GUVENLI FELC BULGUSU: "
                    parts = []
                    if strong_mouth:
                        parts.append("agiz")
                    if strong_brow:
                        parts.append("kas")
                    alert += ", ".join(parts)
                    cv2.putText(
                        frame,
                        alert,
                        (20, 240),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.7,
                        (0, 0, 255),
                        2,
                    )
                    # Ä°stersen burada status'u da zorla "FELÃ‡ (kural)" yapabilirsin
                    # status = "FELÃ‡ (kural)"

                # AnlÄ±k durum
                cv2.putText(
                    frame,
                    status,
                    (20, 80),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.8,
                    (0, 255, 0) if score <= threshold else (0, 0, 255),
                    2,
                )
                # Metrikler (ham deÄŸerler)
                cv2.putText(
                    frame,
                    info,
                    (20, 110),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (255, 255, 255),
                    2,
                )
                # OlasÄ±lÄ±k metni (varsa)
                if prob is not None:
                    cv2.putText(
                        frame,
                        prob_text,
                        (20, 135),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (255, 255, 0),
                        2,
                    )

                # HESAP NASIL YAPILIYOR? KISACA AÃ‡IKLAMA
                cv2.putText(
                    frame,
                    "Skor = 0.3*gÃ¶z + 0.2*aÄŸÄ±z + 0.1*kaÅŸ + 0.4*yÃ¼z",
                    (20, 190),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.55,
                    (200, 255, 200),
                    2,
                )
                cv2.putText(
                    frame,
                    "gÃ¶z/aÄŸÄ±z/kaÅŸ/yÃ¼z: sol-sag asimetri (0â‰ˆsimetrik, yuksekâ‰ˆasimetrik)",
                    (20, 215),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.45,
                    (200, 200, 255),
                    1,
                )

            # KullanÄ±cÄ±ya ne yapmasÄ±nÄ± sÃ¶ylediÄŸimiz bÃ¼yÃ¼k yazÄ±
            cv2.putText(
                frame,
                instruction,
                (20, 40),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.8,
                color,
                2,
            )

            # "Sonrakine geÃ§" butonu
            x1, y1, x2, y2 = NEXT_BTN_RECT
            cv2.rectangle(frame, (x1, y1), (x2, y2), (50, 200, 50), -1)
            cv2.putText(
                frame,
                "Sonrakine gec",
                (x1 + 10, y1 + 25),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 255, 255),
                2,
            )

            cv2.imshow(window_name, frame)

            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC -> tÃ¼m sÃ¼reci bitir
                stop_all = True
                break
            if key == ord("n") or next_clicked:  # 'n' veya buton
                break

        if stop_all or not ret:
            break

    cap.release()
    cv2.destroyAllWindows()

    if not all_scores:
        print("YÃ¼z algÄ±lanamadÄ±, sonuÃ§ Ã¼retilemedi.")
        return

    # Genel ortalama skor
    avg_score = float(np.mean(all_scores))
    result = "FelÃ§ bulgusu var" if avg_score > threshold else "SaÄŸlÄ±klÄ±"
    print(f"\nToplam {len(all_scores)} geÃ§erli kare analiz edildi.")
    print(f"GENEL Ortalama skor: {avg_score:.3f}  ->  {result}")

    # Genel ortalama olasÄ±lÄ±k
    if all_probs:
        avg_prob = float(np.mean(all_probs))
        print(f"GENEL Ortalama felÃ§ olasiligi: {avg_prob*100:5.1f}%")

    # NÃ–TR faz ortalamalarÄ±
    neutral = phase_components.get("notr")
    if neutral and neutral["eye"]:
        notr_eye = float(np.mean(neutral["eye"]))
        notr_mouth = float(np.mean(neutral["mouth"]))
        notr_brow = float(np.mean(neutral["brow"]))
        notr_yuz = float(np.mean(neutral["yuz"]))
        print("\nNÃ–TR faz ortalamalari:")
        print(
            f"  gÃ¶z={notr_eye:.3f}, aÄŸÄ±z={notr_mouth:.3f}, "
            f"kaÅŸ={notr_brow:.3f}, yÃ¼z={notr_yuz:.3f}"
        )
    else:
        notr_eye = notr_mouth = notr_brow = notr_yuz = None
        print("\nNÃ–TR fazdan veri alinamadi.")

    # Faz bazlÄ± ortalamalar ve NÃ–TR'e gÃ¶re farklar
    print("\nFaz bazlÄ± ortalamalar (ve NÃ–TR'e gÃ¶re farklar):")
    for instruction, phase_key, _ in phases:
        scores = phase_scores[phase_key]
        comps = phase_components[phase_key]
        if scores:
            mean_eye = float(np.mean(comps["eye"])) if comps["eye"] else 0.0
            mean_mouth = float(np.mean(comps["mouth"])) if comps["mouth"] else 0.0
            mean_brow = float(np.mean(comps["brow"])) if comps["brow"] else 0.0
            mean_yuz = float(np.mean(comps["yuz"])) if comps["yuz"] else 0.0

            line = (
                f"- {phase_key:12s}: skor={np.mean(scores):.3f} (n={len(scores)})  "
                f"gÃ¶z={mean_eye:.3f}, aÄŸÄ±z={mean_mouth:.3f}, "
                f"kaÅŸ={mean_brow:.3f}, yÃ¼z={mean_yuz:.3f}"
            )

            # NÃ–TR'e gÃ¶re fark
            if notr_eye is not None:
                d_eye = mean_eye - notr_eye
                d_mouth = mean_mouth - notr_mouth
                d_brow = mean_brow - notr_brow
                d_yuz = mean_yuz - notr_yuz
                line += (
                    f"  |  Î”gÃ¶z={d_eye:+.3f}, Î”aÄŸÄ±z={d_mouth:+.3f}, "
                    f"Î”kaÅŸ={d_brow:+.3f}, Î”yÃ¼z={d_yuz:+.3f}"
                )

            # olasÄ±lÄ±k ortalamasÄ±
            probs = phase_probs[phase_key]
            if probs:
                line += f", ort_olasilik={np.mean(probs)*100:5.1f}%"

            print(line)
        else:
            print(f"- {phase_key:12s}: veri yok")


if __name__ == "__main__":
    example = Path("ornekler/felc/felc1.jpg")
    score, details = analyze_face(example)
    if score is None:
        print(details)
    else:
        print(f"Ã–rnek resim skoru: {score:.3f}")
        print(details)

    # Dataset'ten kalibrasyon dene
    calibration = calibrate_from_dataset()

    # Kalibrasyon baÅŸarÄ±lÄ±ysa onunla, deÄŸilse sabit eÅŸikle Ã§alÄ±ÅŸ
    if calibration is not None:
        run_webcam(calibration=calibration, duration=5.0)
    else:
        run_webcam(calibration=None, duration=5.0)